<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>S4N</title>
    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/seven.css">
    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">
    <link rel="stylesheet" href="custom/css/cssimages.css">
    <!-- Printing and PDF exports -->
    <script>
    var link = document.createElement('link');
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
    document.getElementsByTagName('head')[0].appendChild(link);
    </script>
</head>

<body>
    <div id="left"></div>
    <div id="right"></div>
    <div id="top"></div>
    <div id="bottom"></div>
    <div class="reveal">
        <div class="slides">
            <section data-background="url('images/logo_esquina_intro_end.svg'), linear-gradient(to right, #443548, #b71930, #e94635)" data-background-position="right bottom" data-background-repeat="no-repeat">
                <img class="no-border" width="5%" src="images/rombo.svg" />
                <img class="no-border" width="13%" src="images/s4n.svg" />
                <h1 class="white-font">Monitoreo</h1>
                <blockquote class="white-font" width="20px" cite="https://landing.google.com/sre/book/chapters/introduction.html">
                    &ldquo;Es un error teorizar antes de poseer datos, uno comienza a deformar los hechos para hacerlos encajar en las teorías, en vez de ...&rdquo; --Sherlock Holmes
                </blockquote>
            </section>
            <section data-background="url('images/logo_esquina.svg')" data-background-position="right bottom" data-background-repeat="no-repeat">
                <section>
                    <h1>¿Monitoreo?</h1>
                    <p>¿Que?</p>
                    <p>¿Para Quien?</p>
                    <p>¿Cómo?</p>
                </section>
                <section>
                    <h2>¿Qué es Monitoreo?</h2>
                    <p>Herramientas y procesos para medir y manejar sistemas</p>
                    <p>Traducción entre valor y métricas generadas por los sistemas</p>
                    <p>¿Qué falla y por qué?</p>
                </section>
                <section>
                    <h2>¿Para Quien?</h2>
                    <p>Negocio</p>
                    <p>IT</p>
                </section>
                <section>
                    <h2>Tipos de Monitoreo | Modelo de madurez</h2>
                    <ol>
                        <li>Manual (ejecutado por el usuario)</li>
                        <li>Reactivo</li>
                        <li>Proactivo</li>
                    </ol>
                </section>
                <section>
                    <h3>Monitoreo Manual</h3>
                    <p class="fragment">Checklists</p>
                    <p class="fragment">Scripts simples</p>
                    <p class="fragment">Solo lo que ha fallado antes, se soluciona como antes</p>
                    <p class="fragment">Enfoque solo en minimizar downtime</p>
                </section>
                <section>
                    <h3>Monitoreo Reactivo</h3>
                    <p class="fragment">Automático con algúnos rastros manuales</p>
                    <p class="fragment">Alertas con límites simples</p>
                    <p class="fragment">Consolas mostrando estado</p>
                    <p class="fragment">Enfoque en Disponibilida(Infraestructura))</p>
                    <p class="fragment">Actualizacions reactivas</p>
                    <p class="fragment">Nuevas mediciones último paso del despliegue</p>
                </section>
                <section>
                    <h3>Proactivo</h3>
                    <p class="fragment">Nucleo operación</p>
                    <p class="fragment">Automatico génerado por manejo de la configuración</p>
                    <p class="fragment">Las aplicaciónes tienen instrumentación incluida</p>
                    <p class="fragment">Métricas comportamiento applicación y negocio (En contraste con CPU y Disco)</p>
                    <p class="fragment">Calidad del Servicio y Experiencia de Usuario</p>
                    <p class="fragment">Los productos no se consideran completos si no tienen monitoreo</p>
                </section>
                <section>
                    <h2>Enfoque:</h2>
                    <p><b>Estado</b></p>
                    <p>y</p>
                    <p><b>Rendimiento</b></p>
                    <p>a traves de:</p>
                    <p><b>Eventos, Metricas y Logs</b></p>
                </section>
            </section>
            <!--Devops-->
            <section data-background="url('images/logo_esquina.svg')" data-background-position="right bottom" data-background-repeat="no-repeat">
                <section>
                    <img style="float: left" class="no-border" width="10%" src="images/rombo.svg" />
                    <h1>Que monitorear</h1>
                </section>
                <section>
                    <img style="float: left" class="no-border" width="10%" src="images/rombo.svg" />
                    <h2>Monitoreo de</h2>
                    <ul>
                        <li>Negocio</li>
                        <li>Máquina</li>
                        <li>Ambiente</li>
                        <li>Caja Negra</li>
                    </ul>
                </section>
                <section>
                    <h3>Negocio (Whitebox)</h3>
                    <ul>
                        <li>Trázabilidad</li>
                        <li>Por donde a pasado</li>
                        <li>Por donde anda</li>
                    </ul>
                    <p class="fragment">¿Cómo?</p>
                    <p class="fragment">Anlisis Logs( ELK, Cloudwatch metrics, <a target="_blank" href="https://github.com/google/mtail">mtail</a>)</p>
                    <p class="fragment">Instrumentación(
                        <a target="_blank" href="https://docs.oracle.com/javase/9/docs/api/java/lang/instrument/Instrumentation.html">Java</a>,
                        <a target="_blank" href="https://github.com/Netflix/spectator">Netflix Spectator</a>,
                        <a target="_blank" href="https://github.com/prometheus/jmx_exporter">JMX</a>,
                        <a target="_blank" href="https://courses.edx.org/heartbeat">Heartbeat</a>,
                        <a target="_blank" href="https://counter.services.edunext.co/heartbeatcounter/">Heartbeat2</a> )
                    </p>
                </section>
                <section>
                    <h3>Máquina</h3>
                    <ul>
                        <li>Aplicación Instrumentación (Código|Binaria)
                            <ul>
                                <li>Throughput</li>
                                <li>MTTR (Mean Time To respond)</li>
                                <li>Errors (Logs)</li>
                            </ul>
                        </li>
                        <li>OS
                            <ul>
                                <li>Resource Usage</li>
                                <li>Errors</li>
                            </ul>
                        </li>
                    </ul>
                </section>
                <section>
                    <h3>Ambiente</h3>
                    <ul>
                        <li>Red</li>
                        <li>Servicios Usados</li>
                        <li>Interacciones entre Servicios</li>
                    </ul>
                </section>
                <section>
                    <h3>Caja negra</h3>
                    <ul>
                        <li>Usuarios
                            <ul>
                                <li>Origen</li>
                                <li>Cantidad</li>
                                <li>"Tipo"</li>
                                <li>Medio entrada(Navegador, Os, Referer ...)</li>
                            </ul>
                        </li>
                        <li>Aplicación (vista por el usuario)
                            <ul>
                                <li>Latencia</li>
                                <li>Disponibilidad</li>
                                <li>Appdex</li>
                            </ul>
                        </li>
                    </ul>
                </section>
                <section>
                    From google SRE Golden Signals (USE): * Latency * Traffic * Errors * Saturation Utilization (Percentage, ) Saturation (Queue depth) Errors (errors/s) Rate (requests/s) Latency (response time, queue/wait time) Worry about Tail (Dont use averages, histogram with exponential buckets) Resolution of measurements: * should go with SLO * If too frequent use sampling and agregates Monitoring system should be simple * Rules should be simple *
                </section>
                <section>
                    Utilization (Percentage, ) Saturation (Queue depth) Errors (errors/s) Rate (requests/s) Latency (response time, queue/wait time)
                </section>
                <section>
                    <h1>Operacion</h1> SLA, SLO, SLI Monitoreo Alarmas Every alarm should be actionable, First static (Nagios, Zabbix, DataDog) Alarms when definetely wrong Alarms with lower bounds. Dont use averages, use median with short measuring window or percentiles Anomaly Detection Affected by seasonality Newer: Cloud: DataDog, SignalFx On premise: Prometheus, InfluxDb Visualization: Weave Works Splunk Netsil Testing Postmortems: blameless, learn from failure
                </section>
                <section>
                    Cascading failures "If at first you don't succeed, back off exponentially." Dan Sandler, Google Software Engineer
                </section>
                <section>
                    Despliegues Canary A/B Blue Green
                </section>
                <section>
                    Problem Resolution Strategies(http://www.brendangregg.com/methodology.html): Anti-Methodologies: * Blame someone else: 1. Find a system or environment component you are not responsible for 2. Hypothesize that the issue is with that component 3. Redirect the issue to the responsible team 4. When proven wrong, go to 1 * Street Light: 1. Pick observability tools that are: familiar found on the Internet found at random 2. Run tools 3. Look for obvious issues * Drunk Man: 1 Change things at random until the problem goes away * Random Change: 1 Measure a performance baseline 2 Pick a random attribute to change (eg, a tunable) 3 Change it in one direction 4 Measure performance 5 Change it in the other direction 6 Measure performance 7 Were the step 4 or 6 results better than the baseline? If so, keep the change; of not, revert 8 Goto step 1 * Passive Benchmarking Anti-Method: 1 Pick a benchmark tool 2 Run it with a variety of options 3 Make a slide deck of the results 4 Hand the slides to management * Traffic Light 1 Open dashboard 2 All green? Assume everything is good. 3 Something red? Assume that's a problem. Methodologies: * USE (Usage Saturation Error) * List Resources * For every resource, check utilization, saturation, and errors. * RED (Rate Errors Duration) * TSA For each thread measure time in each state, investigate from most to least frequent * Ad hoc checklist * Problem statement What makes you think there is a performance problem? Has this system ever performed well? What has changed recently? (Software? Hardware? Load?) Can the performance degradation be expressed in terms of latency or run time? Does the problem affect other people or applications (or is it just you)? What is the environment? What software and hardware is used? Versions? Configuration? * RTFM * Scientific Method * OODA Observe Orient Decide Act * Work Load characterization * Drill-Down * Elimination (Binary search) * Tools Method List Tools(or add more) For each tool list useful metrics For each metric list interpretation Run selected tools and interpret * CPU profile with flame graph * Performance Evaluation Steps State the goals of the study and define system boundaries List system services and possible outcomes Select performance metrics List system and workload parameters Select factors and their values Select the workload Design the experiments Analyze and interpret the data Present the results If necessary, start over * Capacity Planning Process Instrument the system Monitor system usage Characterize workload Predict performance under different alternatives Select the lowest cost, highest performance alternative
                </section>
                <section>
                    Resumen: Preparedness and Disaster Testing Postmortem Culture Automation and Reduced Operational Overhead Structured and Rational Decision Making
                </section>
                <!--Que gracias-->
                <section data-background="url('images/logo_esquina_intro_end.svg'), linear-gradient(to right, #443548, #b71930, #e94635)" data-background-position="right bottom" data-background-repeat="no-repeat">
                    <h1 class="white-font">Muchas Gracias</h1>
                </section>
        </div>
    </div>
    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>
    <script>
    // More info about config & dependencies:
    // - https://github.com/hakimel/reveal.js#configuration
    // - https://github.com/hakimel/reveal.js#dependencies
    Reveal.initialize({
        defaultTiming: 120,
        zoomKey: 'shift',
        progress: true,
        history: true,
        dependencies: [
            { src: 'plugin/markdown/marked.js' },
            { src: 'plugin/markdown/markdown.js' },
            { src: 'plugin/zoom-js/zoom.js', async: true },
            { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
            { src: 'plugin/notes/notes.js', async: true }
        ]
    });
    </script>
</body>

</html>